# ğŸ¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ensemble Anomaly Detection (Isolation Forest + Autoencoder) Ø¯Ø± Airflow

## ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ - Ø¢Ù¾Ø¯ÛŒØª Ù†Ù‡Ø§ÛŒÛŒ (22 Ø§Ú©ØªØ¨Ø± 2025)

```
ğŸ“¦ Ù¾Ø±ÙˆÚ˜Ù‡: Production-Ready Ensemble Anomaly Detection System
ğŸ“ Ù…Ø³ÛŒØ±: ~/Documents/airflow-docker
â±ï¸ Ø²Ù…Ø§Ù† Ø³Ù¾Ø±ÛŒ Ø´Ø¯Ù‡: ~10 Ø³Ø§Ø¹Øª
â±ï¸ Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ: ~12-15 Ø³Ø§Ø¹Øª
ğŸ“ Ø³Ø·Ø­: Production-Ready Advanced Learning
ğŸ¯ Use Case: Fraud Detection Ø¯Ø± ØµØ±Ø§ÙÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ
```

---

## âœ… Phase 1: Infrastructure Setup (COMPLETED âœ…)

### âœ… Docker & Compose Mastery
```
âœ” Docker Compose architecture
âœ” Services, Volumes, Networks
âœ” Health Checks
âœ” YAML Anchors (&airflow-common)
âœ” User permissions (50000:0 explained!)
```

### âœ… Services Running
```
âœ” PostgreSQL 15 (port 5433)
âœ” Airflow 2.9.0 (webserver: 8080, scheduler)
âœ” ClickHouse 24.1 (HTTP: 8123, Native: 9000)
âœ” All services healthy
```

---

## âœ… Phase 2: Custom Docker Image (COMPLETED âœ…)

### âœ… Files Created
```
âœ” Dockerfile (Ø¨Ø§ uv package manager)
âœ” requirements.txt (clickhouse-connect, pandas, numpy, scikit-learn, matplotlib, tensorflow)
âœ” .dockerignore (build optimization)
âœ” .gitignore (version control)
```

### âœ… Image Built & Running
```
âœ” custom-airflow:2.9.0 Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯
âœ” docker-compose.yml updated
âœ” Ù‡Ù…Ù‡ containers Ø¨Ø§ image Ø¬Ø¯ÛŒØ¯
âœ” Ù‡Ù…Ù‡ packages verified: âœ…
```

### Key Learnings
```
â€¢ Docker layers Ùˆ caching
â€¢ User permissions: 50000:0 = UID:GID
â€¢ Case-sensitive filenames (Dockerfile vs DOCKERFILE)
â€¢ uv vs pip (Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ØªØ±)
```

---

## âœ… Phase 3: Production DAG Development (COMPLETED âœ…)

### âœ… ClickHouse Tables (Ù…ÙˆØ¬ÙˆØ¯)

#### Table 1: sensor_data (Ù…ÙˆØ¬ÙˆØ¯ Ùˆ Ù¾ÙØ± Ø§Ø² data)
```sql
timestamp DateTime
sensor_id String
temperature Float32
humidity Float32
pressure Float32

Status: âœ… 100 records (7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±)
```

#### Table 2: staging_normalized_data (Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡)
```sql
run_id String
timestamp DateTime
sensor_id String
temperature_norm Float32
humidity_norm Float32
pressure_norm Float32
created_at DateTime DEFAULT now()
ENGINE = MergeTree()
ORDER BY (run_id, sensor_id, timestamp)
```

#### Table 3: detected_anomalies (Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡)
```sql
run_id String
dag_id String
execution_time DateTime
timestamp DateTime
sensor_id String
temperature Float32
humidity Float32
pressure Float32
anomaly_score Float32
threshold Float32
anomaly_type String
model_version String
detected_at DateTime DEFAULT now()
ENGINE = MergeTree()
ORDER BY (run_id, timestamp, sensor_id)
```

### âœ… Utils Module (COMPLETED)

#### File: dags/utils/clickhouse_client.py âœ…
```python
âœ” get_clickhouse_client() 
âœ” fetch_sensor_data(start_date, end_date, limit)
âœ” validate_sensor_data(df)
âœ” test_connection()
âœ” Tested & Working
```

### âœ… Test DAG Created & Working (COMPLETED âœ…)

#### File: dags/clickhouse_test_dag.py âœ…
```python
âœ” DAG Configuration
âœ” Task 1: test_clickhouse_connection âœ…
âœ” Task 2: fetch_data âœ…
âœ” Task 3: validate_data âœ…
âœ” Task 4: print_summary âœ…
```

---

## ğŸ¯ Phase 4: Ensemble Models Deep Dive (IN PROGRESS ğŸ”„)

### ğŸ“š ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ ØªØ¦ÙˆØ±ÛŒ (50% âœ…)

#### âœ… Isolation Forest (COMPLETED)
```
âœ” Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø± Isolation Trees
âœ” Path Length Ùˆ Anomaly Score
âœ” Contamination parameter
âœ” Ù…Ø²Ø§ÛŒØ§ Ùˆ Ù…Ø¹Ø§ÛŒØ¨
âœ” Use cases: fraud detection, high-dimensional data
```

#### âœ… Autoencoder (COMPLETED)
```
âœ” Ù…Ø¹Ù…Ø§Ø±ÛŒ Encoder-Decoder
âœ” Latent Space (Bottleneck)
âœ” Reconstruction Error
âœ” Non-linear pattern detection
âœ” Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ PCA
```

#### ğŸ”„ Gradient Descent & Training (IN PROGRESS)
```
â¸ï¸ Forward/Backward Pass
â¸ï¸ Weight Updates
â¸ï¸ Learning Rate
â¸ï¸ Epochs & Convergence
```

#### ğŸ”„ Threshold Selection (IN PROGRESS)
```
â¸ï¸ Percentile-based
â¸ï¸ Statistical (Mean + k*Std)
â¸ï¸ ROC Curve
â¸ï¸ Business-driven thresholds
```

#### â¸ï¸ Ensemble Strategy (TODO)
```
â¸ï¸ Sequential: Autoencoder â†’ Isolation Forest
â¸ï¸ Parallel: Voting mechanism
â¸ï¸ Weighted combination
â¸ï¸ Risk scoring system
```

### ğŸ’» Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„ÛŒ (0%)
```
â¸ï¸ Hands-on Ø¨Ø§ sensor data
â¸ï¸ Training Isolation Forest
â¸ï¸ Training Autoencoder
â¸ï¸ Threshold tuning
â¸ï¸ Ensemble combination testing
```

---

## â¸ï¸ Phase 5: Production Ensemble DAG (TODO 0%)

### â¸ï¸ ClickHouse Tables (New Schema)

#### Table 4: crypto_transactions (Ø¬Ø¯ÛŒØ¯ - Ø¨Ø±Ø§ÛŒ use case ÙˆØ§Ù‚Ø¹ÛŒ)
```sql
CREATE TABLE crypto_transactions (
    transaction_id String,
    timestamp DateTime,
    user_id String,
    amount Float64,
    currency String,
    transaction_type String,  -- 'buy', 'sell', 'withdraw', 'deposit'
    
    -- User behavior
    user_avg_amount Float64,
    user_total_transactions Int32,
    user_account_age_days Int32,
    
    -- Wallet info
    wallet_address String,
    wallet_age_days Int32,
    wallet_total_volume Float64,
    
    -- Context
    hour_of_day Int8,
    day_of_week Int8,
    ip_country String,
    device_type String,
    
    -- Time-based features
    time_since_last_transaction Float64,  -- minutes
    transactions_last_hour Int32,
    transactions_last_24h Int32,
    
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
ORDER BY (timestamp, user_id);
```

#### Table 5: model_registry (Ø¬Ø¯ÛŒØ¯)
```sql
CREATE TABLE model_registry (
    model_id String,
    model_type String,  -- 'isolation_forest', 'autoencoder', 'ensemble'
    version String,
    trained_at DateTime,
    training_samples Int64,
    
    -- Metrics
    precision Float32,
    recall Float32,
    f1_score Float32,
    threshold Float32,
    
    -- Model artifacts
    model_path String,
    scaler_path String,
    
    status String,  -- 'active', 'archived', 'testing'
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
ORDER BY (model_type, trained_at);
```

#### Table 6: detected_anomalies_ensemble (Ø¬Ø¯ÛŒØ¯)
```sql
CREATE TABLE detected_anomalies_ensemble (
    run_id String,
    transaction_id String,
    timestamp DateTime,
    user_id String,
    amount Float64,
    
    -- Layer 1: Statistical
    statistical_risk Float32,
    statistical_flags Array(String),
    
    -- Layer 2: Isolation Forest
    isolation_score Float32,
    isolation_prediction Int8,  -- 1=normal, -1=anomaly
    
    -- Layer 3: Autoencoder
    reconstruction_error Float32,
    autoencoder_prediction Int8,
    latent_features Array(Float32),
    
    -- Final Decision
    total_risk_score Float32,
    final_decision String,  -- 'approved', 'review', 'blocked'
    
    -- Metadata
    model_version String,
    detected_at DateTime DEFAULT now()
) ENGINE = MergeTree()
ORDER BY (run_id, timestamp, user_id);
```

#### Table 7: daily_model_performance (Ø¬Ø¯ÛŒØ¯)
```sql
CREATE TABLE daily_model_performance (
    date Date,
    model_type String,
    
    -- Metrics
    total_predictions Int64,
    anomalies_detected Int64,
    false_positives Int64,  -- if we have labels
    false_negatives Int64,
    
    -- Performance
    avg_latency_ms Float32,
    max_latency_ms Float32,
    
    -- Thresholds used
    threshold_used Float32,
    
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
ORDER BY (date, model_type);
```

---

### â¸ï¸ Models Module (TODO)

#### File: dags/models/isolation_forest_detector.py
```python
â¸ï¸ Class IsolationForestDetector
â¸ï¸ Methods: train, predict, save, load
â¸ï¸ Feature engineering integration
â¸ï¸ Hyperparameter tuning
```

#### File: dags/models/autoencoder_detector.py
```python
â¸ï¸ Class AutoencoderDetector
â¸ï¸ Build model architecture
â¸ï¸ Training with early stopping
â¸ï¸ Reconstruction error calculation
â¸ï¸ Threshold optimization
â¸ï¸ Save/load model & weights
```

#### File: dags/models/ensemble_detector.py
```python
â¸ï¸ Class EnsembleDetector
â¸ï¸ Load both models
â¸ï¸ Statistical checks layer
â¸ï¸ Risk score calculation
â¸ï¸ Final decision logic
â¸ï¸ Monitoring & logging
```

#### File: dags/models/feature_engineering.py
```python
â¸ï¸ extract_features(transactions)
â¸ï¸ time_based_features()
â¸ï¸ user_behavior_features()
â¸ï¸ wallet_features()
â¸ï¸ normalize_features()
```

---

### â¸ï¸ Production DAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DAG: ensemble_anomaly_detection              â”‚
â”‚            Schedule: @hourly                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Task 1: extract_transactions                           â”‚
â”‚  â”œâ”€ Query ClickHouse: last 1 hour transactions         â”‚
â”‚  â””â”€ Output: raw_transactions (XCom)                     â”‚
â”‚                                                          â”‚
â”‚  Task 2: feature_engineering                            â”‚
â”‚  â”œâ”€ Input: raw_transactions                             â”‚
â”‚  â”œâ”€ Create 50+ features:                                â”‚
â”‚  â”‚   â€¢ Amount statistics                                â”‚
â”‚  â”‚   â€¢ Time patterns                                    â”‚
â”‚  â”‚   â€¢ User behavior                                    â”‚
â”‚  â”‚   â€¢ Wallet metadata                                  â”‚
â”‚  â””â”€ Output: feature_matrix (XCom)                       â”‚
â”‚                                                          â”‚
â”‚  Task 3: statistical_layer                              â”‚
â”‚  â”œâ”€ Input: feature_matrix                               â”‚
â”‚  â”œâ”€ Fast rule-based checks:                             â”‚
â”‚  â”‚   â€¢ Amount > 10x average?                            â”‚
â”‚  â”‚   â€¢ 5+ transactions in 5 min?                        â”‚
â”‚  â”‚   â€¢ New wallet + high amount?                        â”‚
â”‚  â”‚   â€¢ Geographic velocity impossible?                  â”‚
â”‚  â””â”€ Output: statistical_scores (XCom)                   â”‚
â”‚                                                          â”‚
â”‚  Task 4: isolation_forest_prediction                    â”‚
â”‚  â”œâ”€ Input: feature_matrix                               â”‚
â”‚  â”œâ”€ Load model: models/isolation_forest_v1.pkl          â”‚
â”‚  â”œâ”€ Predict: anomaly_score & prediction                 â”‚
â”‚  â””â”€ Output: iso_scores (XCom)                           â”‚
â”‚                                                          â”‚
â”‚  Task 5: autoencoder_prediction                         â”‚
â”‚  â”œâ”€ Input: feature_matrix                               â”‚
â”‚  â”œâ”€ Load model: models/autoencoder_v1.h5                â”‚
â”‚  â”œâ”€ Predict: reconstruction_error                       â”‚
â”‚  â””â”€ Output: ae_scores (XCom)                            â”‚
â”‚                                                          â”‚
â”‚  Task 6: ensemble_decision                              â”‚
â”‚  â”œâ”€ Input: all scores (statistical, iso, ae)           â”‚
â”‚  â”œâ”€ Combine:                                            â”‚
â”‚  â”‚   total_risk = stat_score + iso_score + ae_score    â”‚
â”‚  â”œâ”€ Decision:                                           â”‚
â”‚  â”‚   â€¢ risk < 30: Approve                              â”‚
â”‚  â”‚   â€¢ 30-70: Flag for review                          â”‚
â”‚  â”‚   â€¢ > 70: Block                                     â”‚
â”‚  â””â”€ Output: final_decisions (XCom)                      â”‚
â”‚                                                          â”‚
â”‚  Task 7: store_results                                  â”‚
â”‚  â”œâ”€ Input: all data + decisions                         â”‚
â”‚  â””â”€ Insert into detected_anomalies_ensemble             â”‚
â”‚                                                          â”‚
â”‚  Task 8: send_alerts (branch operator)                  â”‚
â”‚  â”œâ”€ If blocked transactions > 0:                        â”‚
â”‚  â”‚   â””â”€ Send notification (email/slack/sms)            â”‚
â”‚  â””â”€ Log summary                                         â”‚
â”‚                                                          â”‚
â”‚  Task 9: update_metrics                                 â”‚
â”‚  â””â”€ Insert into daily_model_performance                 â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Task Dependencies:
extract â†’ feature_eng â†’ [statistical, iso_forest, autoencoder]
                      â†“
                   ensemble_decision
                      â†“
              [store_results, send_alerts, update_metrics]
```

---

### â¸ï¸ Training DAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            DAG: train_ensemble_models                   â”‚
â”‚            Schedule: @weekly (Sunday 02:00)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Task 1: extract_training_data                          â”‚
â”‚  â”œâ”€ Query: last 30 days transactions                    â”‚
â”‚  â”œâ”€ Filter: only NORMAL transactions                    â”‚
â”‚  â”‚   (exclude known frauds)                             â”‚
â”‚  â””â”€ Output: training_data (XCom)                        â”‚
â”‚                                                          â”‚
â”‚  Task 2: feature_engineering_train                      â”‚
â”‚  â”œâ”€ Same pipeline as prediction                         â”‚
â”‚  â””â”€ Output: X_train, scaler                             â”‚
â”‚                                                          â”‚
â”‚  Task 3: train_isolation_forest                         â”‚
â”‚  â”œâ”€ Input: X_train                                      â”‚
â”‚  â”œâ”€ Hyperparameters:                                    â”‚
â”‚  â”‚   â€¢ n_estimators=100                                 â”‚
â”‚  â”‚   â€¢ contamination=0.01                               â”‚
â”‚  â”‚   â€¢ max_features=1.0                                 â”‚
â”‚  â”œâ”€ Save: models/isolation_forest_v{version}.pkl        â”‚
â”‚  â””â”€ Output: model_path, metrics                         â”‚
â”‚                                                          â”‚
â”‚  Task 4: train_autoencoder                              â”‚
â”‚  â”œâ”€ Input: X_train (normalized)                         â”‚
â”‚  â”œâ”€ Architecture:                                       â”‚
â”‚  â”‚   Input(50) â†’ Dense(30) â†’ Dense(10) [Latent]        â”‚
â”‚  â”‚           â†’ Dense(30) â†’ Dense(50) [Output]          â”‚
â”‚  â”œâ”€ Training:                                           â”‚
â”‚  â”‚   â€¢ epochs=50                                        â”‚
â”‚  â”‚   â€¢ batch_size=32                                    â”‚
â”‚  â”‚   â€¢ early_stopping (patience=5)                      â”‚
â”‚  â”œâ”€ Save: models/autoencoder_v{version}.h5              â”‚
â”‚  â””â”€ Output: model_path, metrics, threshold              â”‚
â”‚                                                          â”‚
â”‚  Task 5: calculate_thresholds                           â”‚
â”‚  â”œâ”€ Input: X_train, both models                         â”‚
â”‚  â”œâ”€ Calculate optimal thresholds:                       â”‚
â”‚  â”‚   â€¢ Isolation Forest: score threshold               â”‚
â”‚  â”‚   â€¢ Autoencoder: reconstruction error threshold      â”‚
â”‚  â”‚   Strategy: 95th percentile                          â”‚
â”‚  â””â”€ Output: thresholds                                  â”‚
â”‚                                                          â”‚
â”‚  Task 6: validate_models                                â”‚
â”‚  â”œâ”€ Input: validation set (20% of data)                â”‚
â”‚  â”œâ”€ Calculate metrics:                                  â”‚
â”‚  â”‚   â€¢ Precision, Recall, F1                            â”‚
â”‚  â”‚   â€¢ ROC-AUC (if labels available)                    â”‚
â”‚  â”‚   â€¢ Latency tests                                    â”‚
â”‚  â””â”€ Output: validation_metrics                          â”‚
â”‚                                                          â”‚
â”‚  Task 7: register_models                                â”‚
â”‚  â”œâ”€ Insert into model_registry table                    â”‚
â”‚  â”œâ”€ Version: v{date}_{git_commit}                       â”‚
â”‚  â””â”€ Status: 'testing'                                   â”‚
â”‚                                                          â”‚
â”‚  Task 8: a_b_test (optional)                            â”‚
â”‚  â”œâ”€ Route 10% traffic to new models                     â”‚
â”‚  â”œâ”€ Compare performance with current models              â”‚
â”‚  â””â”€ Decision: promote or rollback                       â”‚
â”‚                                                          â”‚
â”‚  Task 9: promote_to_production                          â”‚
â”‚  â”œâ”€ If validation successful:                           â”‚
â”‚  â”‚   â€¢ Update model_registry: status='active'           â”‚
â”‚  â”‚   â€¢ Archive old models: status='archived'            â”‚
â”‚  â””â”€ Send notification                                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Task Dependencies:
extract â†’ feature_eng â†’ [train_iso, train_ae]
                      â†“
              calculate_thresholds â†’ validate
                                   â†“
                          [register, a_b_test] â†’ promote
```

---

## ğŸ“Š Current Architecture (Updated)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker Network                         â”‚
â”‚                  (airflow_network)                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  PostgreSQL  â”‚â—„â”€â”€â”€â”€â”€â”¤   Airflow    â”‚                â”‚
â”‚  â”‚   (Metadata) â”‚      â”‚  Scheduler   â”‚                â”‚
â”‚  â”‚   + XCom     â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                         â”‚
â”‚         â–²                      â–¼                         â”‚
â”‚         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â”‚              â”‚   Airflow    â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  Webserver   â”‚                 â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                          â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                        â”‚  ClickHouse  â”‚                 â”‚
â”‚                        â”‚  7 tables:   â”‚                 â”‚
â”‚                        â”‚  â€¢ sensor              (100)   â”‚
â”‚                        â”‚  â€¢ staging             (ready) â”‚
â”‚                        â”‚  â€¢ anomalies           (ready) â”‚
â”‚                        â”‚  â€¢ crypto_transactions (TODO)  â”‚
â”‚                        â”‚  â€¢ model_registry      (TODO)  â”‚
â”‚                        â”‚  â€¢ detected_ensemble   (TODO)  â”‚
â”‚                        â”‚  â€¢ performance         (TODO)  â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                          â”‚
â”‚  Volumes:                                               â”‚
â”‚  â€¢ ./dags â†’ /opt/airflow/dags                          â”‚
â”‚  â€¢ ./logs â†’ /opt/airflow/logs                          â”‚
â”‚  â€¢ ./models â†’ /opt/airflow/models (NEW!)               â”‚
â”‚                                                          â”‚
â”‚  Custom Image: custom-airflow:2.9.0                    â”‚
â”‚  + TensorFlow, scikit-learn                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure (Updated)

```
airflow-docker/
â”œâ”€â”€ docker-compose.yml              # âœ… Using custom-airflow:2.9.0
â”œâ”€â”€ Dockerfile                      # âœ… With uv + TensorFlow
â”œâ”€â”€ requirements.txt                # âœ… All packages + TF
â”œâ”€â”€ .dockerignore                   # âœ… Build optimization
â”œâ”€â”€ .gitignore                      # âœ… Version control
â”œâ”€â”€ roadmap_ensemble_v2.md          # âœ… This file (UPDATED!)
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ hello_world_dag.py                    # âœ… Working
â”‚   â”œâ”€â”€ clickhouse_test_dag.py                # âœ… COMPLETED & TESTED
â”‚   â”œâ”€â”€ generate_fresh_data.py                # âœ… Data generator
â”‚   â”‚
â”‚   â”œâ”€â”€ ensemble_anomaly_detection.py         # â¸ï¸ TODO (main DAG)
â”‚   â”œâ”€â”€ train_ensemble_models.py              # â¸ï¸ TODO (training DAG)
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py                       # âœ… Empty
â”‚   â”‚   â”œâ”€â”€ clickhouse_client.py              # âœ… COMPLETED
â”‚   â”‚   â””â”€â”€ feature_engineering.py            # â¸ï¸ TODO
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py                       # â¸ï¸ TODO
â”‚       â”œâ”€â”€ isolation_forest_detector.py      # â¸ï¸ TODO
â”‚       â”œâ”€â”€ autoencoder_detector.py           # â¸ï¸ TODO
â”‚       â””â”€â”€ ensemble_detector.py              # â¸ï¸ TODO
â”‚
â”œâ”€â”€ models/                         # â¸ï¸ NEW! Saved models directory
â”‚   â”œâ”€â”€ isolation_forest_v1.pkl
â”‚   â”œâ”€â”€ autoencoder_v1.h5
â”‚   â”œâ”€â”€ scaler_v1.pkl
â”‚   â””â”€â”€ thresholds_v1.json
â”‚
â”œâ”€â”€ logs/                           # Airflow logs
â”œâ”€â”€ notebooks/                      # â¸ï¸ NEW! For experiments
â”‚   â”œâ”€â”€ 01_explore_data.ipynb
â”‚   â”œâ”€â”€ 02_isolation_forest_test.ipynb
â”‚   â”œâ”€â”€ 03_autoencoder_test.ipynb
â”‚   â””â”€â”€ 04_ensemble_tuning.ipynb
â”‚
â””â”€â”€ plugins/                        # Empty for now
```

---

## ğŸ¯ Ù…Ø³ÛŒØ± ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ (Ø¨Ø§ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… Phase 1: Infrastructure (DONE - 100%)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Phase 2: Custom Docker Image (DONE - 100%)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Phase 3: Production DAG (DONE - 100%)              â”‚
â”‚  âœ… ClickHouse tables created                          â”‚
â”‚  âœ… utils/clickhouse_client.py completed               â”‚
â”‚  âœ… clickhouse_test_dag.py tested                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”„ Phase 4: Ensemble Models Deep Dive (50%) âœ¨        â”‚
â”‚  âœ… Isolation Forest theory (100%)                     â”‚
â”‚  âœ… Autoencoder theory (100%)                          â”‚
â”‚  ğŸ”„ Gradient Descent & Training (0%) â† NEXT!          â”‚
â”‚  ğŸ”„ Threshold Selection (0%) â† NEXT!                  â”‚
â”‚  â¸ï¸  Ensemble Strategy (0%)                            â”‚
â”‚  â¸ï¸  Hands-on implementation (0%)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â¸ï¸  Phase 5: Ensemble DAG Production (0%)            â”‚
â”‚  â¸ï¸  New ClickHouse tables                            â”‚
â”‚  â¸ï¸  Models module                                     â”‚
â”‚  â¸ï¸  Feature engineering                               â”‚
â”‚  â¸ï¸  Training DAG                                      â”‚
â”‚  â¸ï¸  Prediction DAG                                    â”‚
â”‚  â¸ï¸  Testing & Validation                              â”‚
â”‚  â¸ï¸  Monitoring & Alerts                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â¸ï¸  Phase 6: Advanced Features (Optional)            â”‚
â”‚  â¸ï¸  A/B Testing                                       â”‚
â”‚  â¸ï¸  Real-time streaming (Kafka)                       â”‚
â”‚  â¸ï¸  Dashboard (Grafana)                               â”‚
â”‚  â¸ï¸  Model drift detection                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡ ØªØ®Ù…ÛŒÙ†ÛŒ:
â€¢ Phase 4 (Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡): 2-3 Ø³Ø§Ø¹Øª
â€¢ Phase 5: 8-10 Ø³Ø§Ø¹Øª
â€¢ Phase 6 (optional): 4-6 Ø³Ø§Ø¹Øª
â€¢ Ø¬Ù…Ø¹: 12-15 Ø³Ø§Ø¹Øª
```

---

## ğŸ“š Key Learnings So Far

### Docker & Infrastructure
```
â€¢ User permissions: 50000:0 (UID:GID)
â€¢ Docker layer caching
â€¢ .dockerignore for speed
â€¢ Volume mounting: ./dags â†’ /opt/airflow/dags
â€¢ Port mapping: ClickHouse 8123 (HTTP), 9000 (Native)
â€¢ Container networking: service names as hostnames
```

### ClickHouse
```
â€¢ Port 8123 Ø¨Ø±Ø§ÛŒ HTTP API (clickhouse_connect)
â€¢ Port 9000 Ø¨Ø±Ø§ÛŒ Native protocol (CLI)
â€¢ MergeTree engine
â€¢ ORDER BY for indexing
â€¢ Pressure unit: hPa (1013) Ù†Ù‡ Pascal (101300)
â€¢ datetime formatting: strftime('%Y-%m-%d %H:%M:%S')
â€¢ Insert vs Query: datetime object vs string!
```

### Python & Pandas
```
â€¢ DataFrame vs Dataframe (case-sensitive!)
â€¢ pd.DataFrame(data, columns=[...])
â€¢ Type hints: Optional[datetime], pd.DataFrame
â€¢ Validation patterns (empty, null, range checks)
â€¢ datetime.strftime() for formatting
â€¢ datetime objects vs strings
```

### Airflow Concepts
```
â€¢ DAG structure & configuration
â€¢ PythonOperator, BranchOperator
â€¢ Task dependencies (>>)
â€¢ XCom for data passing between tasks
â€¢ context and **context parameter
â€¢ context['ti'].xcom_pull(task_ids='...')
â€¢ Manual vs scheduled DAGs
â€¢ Retry configuration
â€¢ Health checks & depends_on
```

### Machine Learning Concepts (NEW!)
```
â€¢ Isolation Forest:
  - Tree-based anomaly detection
  - Path length = anomaly score
  - Fast & scalable
  
â€¢ Autoencoder:
  - Neural network for reconstruction
  - Encoder â†’ Latent Space â†’ Decoder
  - Reconstruction error = anomaly indicator
  - Non-linear pattern detection
  
â€¢ Ensemble:
  - Combining multiple models
  - Weighted risk scoring
  - Multi-layer architecture
  - Better accuracy + lower false positives
```

### Production Mindset
```
â€¢ Start simple, then add complexity
â€¢ Validation before processing
â€¢ Modular code (utils/, models/)
â€¢ Test individual components first
â€¢ Meaningful log messages
â€¢ Error handling
â€¢ Model versioning & registry
â€¢ A/B testing for new models
â€¢ Monitoring & alerting
```

---

## ğŸ’» Essential Commands (Updated)

### Docker Management
```bash
# Service status
docker compose ps

# Full restart
docker compose down
docker compose up -d

# Logs
docker compose logs -f scheduler
docker compose logs -f webserver
docker logs airflow_scheduler --tail 50

# Rebuild image (with TensorFlow now!)
docker build -t custom-airflow:2.9.0 .

# Restart services
docker compose restart scheduler webserver
```

### ClickHouse CLI
```bash
# Connect
docker exec -it airflow_clickhouse clickhouse-client \
  --user airflow \
  --password clickhouse1234 \
  --database analytics

# Direct query
docker exec -it airflow_clickhouse clickhouse-client \
  --user airflow \
  --password clickhouse1234 \
  --database analytics \
  --query "SELECT COUNT(*) FROM sensor_data"

# Inside CLI:
SHOW TABLES;
DESCRIBE TABLE crypto_transactions;
SELECT * FROM detected_anomalies_ensemble LIMIT 5;
```

### Airflow CLI
```bash
# List DAGs
docker exec -it airflow_webserver airflow dags list

# Trigger training DAG
docker exec -it airflow_webserver airflow dags trigger train_ensemble_models

# Trigger prediction DAG
docker exec -it airflow_webserver airflow dags trigger ensemble_anomaly_detection

# List DAG runs
docker exec -it airflow_webserver airflow dags list-runs -d ensemble_anomaly_detection

# Test specific task
docker exec -it airflow_webserver \
  airflow tasks test ensemble_anomaly_detection isolation_forest_prediction 2025-10-22
```

### Python Scripts in Container
```bash
# Run Python script
docker exec -it airflow_webserver python /opt/airflow/dags/generate_crypto_data.py

# Test models module
docker exec -it airflow_webserver \
  python /opt/airflow/dags/models/isolation_forest_detector.py

# Interactive Python
docker exec -it airflow_webserver python
>>> from models.ensemble_detector import EnsembleDetector
>>> detector = EnsembleDetector()
```

---

## ğŸŒ Access Points

```
Airflow Dashboard:
â†’ http://localhost:8080
   Username: admin
   Password: admin1234
   Status: âœ… WORKING
   DAGs: 
      â€¢ clickhouse_test_dag (âœ… SUCCESS)
      â€¢ ensemble_anomaly_detection (â¸ï¸ TODO)
      â€¢ train_ensemble_models (â¸ï¸ TODO)

ClickHouse HTTP:
â†’ http://localhost:8123
   Status: âœ… WORKING
   Database: analytics
   Tables: 7 (3 active, 4 TODO)

ClickHouse Native:
â†’ localhost:9000
   User: airflow
   Password: clickhouse1234
   Database: analytics
   Status: âœ… WORKING
```

---

## ğŸ› Common Issues & Solutions

### Issue 1: TensorFlow Import Error
```
Error: ModuleNotFoundError: No module named 'tensorflow'
Solution: Rebuild Docker image with updated requirements.txt
```

### Issue 2: Model File Not Found
```
Error: FileNotFoundError: models/autoencoder_v1.h5
Solution: Ensure models directory is mounted as volume
```

### Issue 3: High Memory Usage (Autoencoder Training)
```
Error: OOM (Out of Memory)
Solution: 
  - Reduce batch_size
  - Use smaller model architecture
  - Increase Docker memory limit
```

### Issue 4: Gradient Descent Not Converging
```
Error: Loss not decreasing
Solution:
  - Adjust learning_rate (try 0.01, 0.001, 0.0001)
  - Check data normalization
  - Increase epochs
  - Try different optimizer (Adam vs SGD)
```

---

## ğŸ“Š Ú†Ú©â€ŒÙ„ÛŒØ³Øª Ù¾ÛŒØ´Ø±ÙØª Ø¯Ù‚ÛŒÙ‚

### âœ… Infrastructure (100%)
- [x] Docker Compose setup
- [x] PostgreSQL running (healthy)
- [x] Airflow webserver & scheduler (healthy)
- [x] ClickHouse running (healthy)
- [x] All services healthy
- [x] Network connectivity verified

### âœ… Custom Image (100%)
- [x] Dockerfile created
- [x] requirements.txt with TensorFlow
- [x] Image built: custom-airflow:2.9.0
- [x] docker-compose.yml updated
- [x] Packages verified working
- [x] .dockerignore & .gitignore created

### âœ… ClickHouse Integration (100%)
- [x] ClickHouse running
- [x] sensor_data table (100 records)
- [x] staging_normalized_data table
- [x] detected_anomalies table
- [x] utils/clickhouse_client.py completed
- [x] Connection tested successfully
- [x] Data fetch working
- [x] Validation tested & passed
- [x] clickhouse_test_dag.py working
- [x] End-to-end pipeline tested âœ…

### ğŸ”„ Ensemble Models Learning (50%)
- [x] Isolation Forest theory
- [x] Autoencoder theory (Encoder/Decoder)
- [ ] Gradient Descent & Training (IN PROGRESS)
- [ ] Threshold Selection strategies
- [ ] Ensemble combination strategies
- [ ] Hands-on implementation

### â¸ï¸ Production Ensemble DAG (0%)
- [ ] New ClickHouse tables created
- [ ] Models module structure
- [ ] Feature engineering pipeline
- [ ] Training DAG implemented
- [ ] Prediction DAG implemented
- [ ] Model registry system
- [ ] Testing & validation
- [ ] Monitoring & alerts

---

## ğŸ¯ Ù‚Ø¯Ù… Ø¨Ø¹Ø¯ÛŒ Ù…Ø´Ø®Øµ

**Ø§Ù„Ø§Ù† Ø¯Ø± Phase 4 Ù‡Ø³ØªÛŒÙ…:**

### Session Ø¨Ø¹Ø¯ÛŒ (2-3 Ø³Ø§Ø¹Øª):
```
1. Gradient Descent & Training (1 Ø³Ø§Ø¹Øª)
   - ØªÙˆØ¶ÛŒØ­ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¨Ø§ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ØªØ±
   - Forward/Backward pass Ø¨Ø§ Ø§Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ
   - Weight update mechanism
   - Convergence Ùˆ stopping criteria

2. Threshold Selection (1 Ø³Ø§Ø¹Øª)
   - Percentile method (Ø¨Ø§ Ù…Ø«Ø§Ù„)
   - Statistical methods
   - ROC curve approach
   - Business-driven thresholds
   - Threshold per model Ø¯Ø± Ensemble

3. Hands-on Practice (30 Ø¯Ù‚ÛŒÙ‚Ù‡ - optional)
   - ØªØ³Øª Ú©ÙˆÚ†Ú© Ø¨Ø§ sensor data
   - Visualization
```

---

## ğŸš€ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Session Ø¨Ø¹Ø¯ÛŒ!

**Ø¯Ø± Ú†Øª Ø¬Ø¯ÛŒØ¯:**
1. Ø§ÛŒÙ† roadmap Ø±Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†
2. Ø¨Ú¯Ùˆ: "Phase 4 Ø±Ùˆ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÛŒÙ… - Gradient Descent Ùˆ Threshold"
3. Ù…Ù† Ø¨Ø§ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ **Ø¨Ù‡ØªØ± Ùˆ ÙˆØ§Ø¶Ø­â€ŒØªØ±** ØªÙˆØ¶ÛŒØ­ Ù…ÛŒØ¯Ù…!

**ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ:**
- âœ… Infrastructure: 100%
- âœ… Docker & Airflow: 100%  
- âœ… ClickHouse: 100%
- âœ… Test DAG: 100%
- âœ… Isolation Forest: 100%
- âœ… Autoencoder: 100%
- ğŸ”„ Gradient Descent: 0% â† NEXT!
- ğŸ”„ Threshold Selection: 0% â† NEXT!
- ğŸ¯ Ensemble DAG: 0%

**Achievement Unlocked:** ğŸ†
- Ensemble Architecture Designed âœ…
- New ClickHouse Schema Ready âœ…
- 7-table production setup âœ…
- Comprehensive roadmap updated âœ…

Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒ Ø¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Phase 4! ğŸ‰