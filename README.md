# ğŸ¯ Ensemble Anomaly Detection System

Production-ready ensemble anomaly detection system for crypto transaction fraud detection using Airflow, ClickHouse, Isolation Forest, and Autoencoder.

## ğŸ“‹ Overview

This system detects fraudulent cryptocurrency transactions using a 3-layer ensemble approach:

1. **Statistical Layer**: Fast rule-based checks for obvious anomalies
2. **Isolation Forest**: Tree-based anomaly detection for high-dimensional patterns
3. **Autoencoder**: Neural network reconstruction for non-linear anomaly detection

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Docker Compose Stack                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PostgreSQL  â”‚  â”‚   Airflow    â”‚  â”‚  ClickHouse  â”‚ â”‚
â”‚  â”‚  (Metadata)  â”‚  â”‚  Scheduler   â”‚  â”‚  (Analytics) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Webserver   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.9+
- 8GB+ RAM
- Ports available: 8080, 8123, 9000, 5433

### Installation

1. **Clone and setup:**
```bash
git clone <your-repo>
cd airflow-docker
```

2. **Build custom Airflow image:**
```bash
docker build -t custom-airflow:2.9.0 .
```

3. **Start services:**
```bash
docker compose up -d
```

4. **Initialize ClickHouse tables:**
```bash
docker cp scripts/init_clickhouse_tables.sql airflow_clickhouse:/tmp/
docker exec airflow_clickhouse clickhouse-client \
  --user airflow --password clickhouse1234 --database analytics \
  --multiquery < /tmp/init_clickhouse_tables.sql
```

5. **Import data (if you have transactions.csv):**
```bash
docker cp scripts/import_transactions.py airflow_webserver:/tmp/
docker exec airflow_webserver python /tmp/import_transactions.py
```

6. **Access Airflow UI:**
- URL: http://localhost:8080
- Username: `admin`
- Password: `admin1234`

### Usage

#### Training Models

```bash
# Trigger training DAG (runs weekly by default)
docker exec airflow_webserver airflow dags trigger train_ensemble_models
```

Wait 5-10 minutes for training to complete. Models will be saved to `/opt/airflow/models/`.

#### Running Detection

```bash
# Trigger detection DAG (runs hourly by default)
docker exec airflow_webserver airflow dags trigger ensemble_anomaly_detection
```

Or enable the DAG in UI for automatic hourly runs.

## ğŸ“Š Querying Results

### Check recent detections:
```sql
SELECT 
    risk_level,
    final_decision,
    count() as cnt
FROM detected_anomalies_ensemble
WHERE detected_at >= now() - INTERVAL 24 HOUR
GROUP BY risk_level, final_decision;
```

### View high-risk transactions:
```sql
SELECT 
    transaction_id,
    user_id,
    amount,
    total_risk_score,
    risk_level,
    final_decision
FROM detected_anomalies_ensemble
WHERE risk_level IN ('high', 'critical')
ORDER BY total_risk_score DESC
LIMIT 10;
```

## ğŸ§ª Testing

Insert test data:
```bash
docker cp scripts/insert_test_data_recent.py airflow_webserver:/tmp/
docker exec airflow_webserver python /tmp/insert_test_data_recent.py
```

## ğŸ“ Project Structure

```
airflow-docker/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ ensemble_anomaly_detection.py    # Production DAG
â”‚   â”œâ”€â”€ train_ensemble_models.py          # Training DAG
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ isolation_forest_detector.py
â”‚   â”‚   â”œâ”€â”€ autoencoder_detector.py
â”‚   â”‚   â””â”€â”€ ensemble_detector.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ clickhouse_client.py
â”‚       â””â”€â”€ feature_engineering.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_clickhouse_tables.sql
â”‚   â””â”€â”€ import_transactions.py
â”œâ”€â”€ models/                               # Saved ML models
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## ğŸ”§ Configuration

### Environment Variables

Edit `docker-compose.yml` to configure:
- Database credentials
- Resource limits
- Volume mounts

### Model Parameters

Edit `dags/train_ensemble_models.py`:
- Training frequency: `schedule_interval='0 2 * * 0'` (weekly)
- Training window: `TRAINING_DAYS = 30`
- Model hyperparameters in detector classes

### Detection Parameters

Edit `dags/ensemble_anomaly_detection.py`:
- Detection frequency: `schedule_interval='0 * * * *'` (hourly)
- Risk thresholds in `EnsembleDetector`

## ğŸ“ˆ Performance

Typical performance on 1000 transactions:
- Feature extraction: ~2s
- Isolation Forest: ~0.1s
- Autoencoder: ~0.3s
- Total: ~3s (3ms per transaction)

## ğŸ› Troubleshooting

### DAG not visible
```bash
docker compose restart scheduler
```

### Models not loading
```bash
# Check model registry
docker exec airflow_clickhouse clickhouse-client \
  --user airflow --password clickhouse1234 --database analytics \
  --query "SELECT * FROM model_registry WHERE status='active'"
```

### Check logs
```bash
docker logs airflow_scheduler -f
docker logs airflow_webserver -f
```

## ğŸ“ License

MIT License - feel free to use for your projects!

## ğŸ™ Acknowledgments

Built with:
- Apache Airflow 2.9.0
- ClickHouse 24.1
- TensorFlow/Keras 2.x
- scikit-learn
- pandas, numpy

---

**Ready for production!** ğŸš€
