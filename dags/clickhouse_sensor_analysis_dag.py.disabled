"""
DAG برای تست اتصال به ClickHouse و خواندن داده‌های sensor_data
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
import clickhouse_connect

# تنظیمات پیش‌فرض DAG
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 10, 15),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def test_clickhouse_connection():
    """
    تست اتصال به ClickHouse
    """
    try:
        # اتصال به ClickHouse
        client = clickhouse_connect.get_client(
            host='clickhouse',
            port=8123,
            username='airflow',
            password='clickhouse1234',
            database='analytics'
        )
        
        # تست ساده
        result = client.command('SELECT version()')
        print(f"✅ اتصال موفق! ClickHouse Version: {result}")
        
        return "Connection successful"
    
    except Exception as e:
        print(f"❌ خطا در اتصال: {str(e)}")
        raise


def fetch_sensor_data():
    """
    خواندن داده‌های sensor_data از ClickHouse
    """
    try:
        # اتصال
        client = clickhouse_connect.get_client(
            host='clickhouse',
            port=8123,
            username='airflow',
            password='clickhouse1234',
            database='analytics'
        )
        
        # Query
        query = """
        SELECT 
            timestamp,
            sensor_id,
            temperature,
            humidity,
            pressure
        FROM sensor_data
        ORDER BY timestamp
        """
        
        # اجرای query
        result = client.query(query)
        
        # نمایش نتایج
        print(f"\n{'='*60}")
        print(f"📊 تعداد کل رکوردها: {len(result.result_rows)}")
        print(f"{'='*60}\n")
        
        # نمایش 5 رکورد اول
        print("📋 5 رکورد اول:\n")
        print(f"{'Timestamp':<20} {'Sensor':<10} {'Temp':<8} {'Humid':<8} {'Press':<10}")
        print("-" * 60)
        
        for row in result.result_rows[:5]:
            timestamp, sensor_id, temp, humid, press = row
            print(f"{str(timestamp):<20} {sensor_id:<10} {temp:<8.2f} {humid:<8.2f} {press:<10.2f}")
        
        if len(result.result_rows) > 5:
            print(f"\n... و {len(result.result_rows) - 5} رکورد دیگر\n")
        
        # آمار کلی
        print(f"\n{'='*60}")
        print("📈 آمار داده‌ها:")
        print(f"{'='*60}")
        
        # محاسبه آمار با Python
        temps = [row[2] for row in result.result_rows]
        humids = [row[3] for row in result.result_rows]
        pressures = [row[4] for row in result.result_rows]
        
        print(f"🌡️  Temperature: min={min(temps):.2f}, max={max(temps):.2f}, avg={sum(temps)/len(temps):.2f}")
        print(f"💧 Humidity:    min={min(humids):.2f}, max={max(humids):.2f}, avg={sum(humids)/len(humids):.2f}")
        print(f"🌬️  Pressure:    min={min(pressures):.2f}, max={max(pressures):.2f}, avg={sum(pressures)/len(pressures):.2f}")
        
        # سنسورهای موجود
        sensors = list(set([row[1] for row in result.result_rows]))
        print(f"\n🎯 سنسورهای موجود: {', '.join(sensors)}")
        print(f"{'='*60}\n")
        
        return len(result.result_rows)
    
    except Exception as e:
        print(f"❌ خطا در خواندن داده: {str(e)}")
        raise


def analyze_sensor_stats(**context):
    """
    آنالیز پیشرفته‌تر داده‌ها
    """
    try:
        client = clickhouse_connect.get_client(
            host='clickhouse',
            port=8123,
            username='airflow',
            password='clickhouse1234',
            database='analytics'
        )
        
        # Query برای آمار هر سنسور
        query = """
        SELECT 
            sensor_id,
            COUNT(*) as record_count,
            AVG(temperature) as avg_temp,
            AVG(humidity) as avg_humid,
            AVG(pressure) as avg_press,
            MIN(temperature) as min_temp,
            MAX(temperature) as max_temp
        FROM sensor_data
        GROUP BY sensor_id
        ORDER BY sensor_id
        """
        
        result = client.query(query)
        
        print(f"\n{'='*80}")
        print("📊 آمار تفکیکی هر سنسور")
        print(f"{'='*80}\n")
        
        print(f"{'Sensor':<12} {'Count':<8} {'Avg Temp':<10} {'Avg Humid':<12} {'Avg Press':<12} {'Temp Range':<15}")
        print("-" * 80)
        
        for row in result.result_rows:
            sensor_id, count, avg_t, avg_h, avg_p, min_t, max_t = row
            temp_range = f"{min_t:.1f}-{max_t:.1f}"
            print(f"{sensor_id:<12} {count:<8} {avg_t:<10.2f} {avg_h:<12.2f} {avg_p:<12.2f} {temp_range:<15}")
        
        print(f"\n{'='*80}\n")
        
        # ذخیره تعداد رکوردها برای task بعدی (در XCom)
        ti = context['ti']
        total_records = sum([row[1] for row in result.result_rows])
        ti.xcom_push(key='total_records', value=total_records)
        
        print(f"✅ تعداد کل رکوردها ({total_records}) در XCom ذخیره شد")
        
        return "Analysis completed"
    
    except Exception as e:
        print(f"❌ خطا در آنالیز: {str(e)}")
        raise


def print_summary(**context):
    """
    خلاصه نهایی
    """
    ti = context['ti']
    total_records = ti.xcom_pull(key='total_records', task_ids='analyze_stats')
    
    print(f"\n{'='*60}")
    print("🎉 خلاصه اجرا")
    print(f"{'='*60}")
    print(f"✅ اتصال به ClickHouse: موفق")
    print(f"✅ خواندن داده: موفق")
    print(f"✅ آنالیز: موفق")
    print(f"📊 تعداد کل رکوردها: {total_records}")
    print(f"{'='*60}\n")
    
    print("🎯 آماده برای مرحله بعدی: پیاده‌سازی PCA!")


# تعریف DAG
with DAG(
    'clickhouse_sensor_test',
    default_args=default_args,
    description='تست اتصال به ClickHouse و خواندن داده‌های سنسور',
    schedule_interval=None,  # فقط manual trigger
    catchup=False,
    tags=['clickhouse', 'test', 'sensors'],
) as dag:
    
    # Task 1: تست اتصال
    test_connection = PythonOperator(
        task_id='test_connection',
        python_callable=test_clickhouse_connection,
    )
    
    # Task 2: خواندن داده
    fetch_data = PythonOperator(
        task_id='fetch_data',
        python_callable=fetch_sensor_data,
    )
    
    # Task 3: آنالیز آماری
    analyze_stats = PythonOperator(
        task_id='analyze_stats',
        python_callable=analyze_sensor_stats,
        provide_context=True,
    )
    
    # Task 4: خلاصه نهایی
    summary = PythonOperator(
        task_id='print_summary',
        python_callable=print_summary,
        provide_context=True,
    )
    
    # تعریف ترتیب اجرا
    test_connection >> fetch_data >> analyze_stats >> summary
